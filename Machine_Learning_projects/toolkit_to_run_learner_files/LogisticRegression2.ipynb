{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the digits database and scikit-learn\n",
    "\n",
    "1. Split your data into 30% test and 70% training sets, \n",
    "2. For each of the values of $C = 10^{k}$ for $k = {-10,...,10}$ train an $L^{2}$ regularized logistic regression model with regularization weight lambda = $\\frac{1}{C}$  (this is the default form for scikit-learn) on the training set and compute the mean accuracy on the test set for each model.  Which performed best?  \n",
    "3. Repeat #2 with $L^{1}$ regularization instead of $L^{2}$.  Do the results suggest any features that can be dropped from the data set?\n",
    "4. Scikit-learn does not have logistic regression without regularization.  What values of $C$ are most similar to an un-regularized model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.\n",
    "digits = datasets.load_digits()\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(digits.data, digits.target, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953703703704 is the greatest score from 10** -2\n"
     ]
    }
   ],
   "source": [
    "#2.\n",
    "l=[]\n",
    "nums=range(-10,11)\n",
    "for i in range(-10,11):\n",
    "    log = LogisticRegression(penalty=\"l2\",C=10**i)\n",
    "    results = log.fit(Xtrain, ytrain)\n",
    "    l.append(results.score(Xtest, ytest))\n",
    "print(max(l),\"is the greatest score from 10**\",nums[l.index(max(l))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955555555556 is the greatest score from 10** -1\n",
      "We can drop all features whose coeffs are less than our confidence interval\n",
      "Really big values of C are most similar to un-regularized model\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "l=[]\n",
    "for i in range(-10,11):\n",
    "    log = LogisticRegression(penalty=\"l1\",C=10**i)\n",
    "    results = log.fit(Xtrain, ytrain)\n",
    "    l.append(results.score(Xtest, ytest))\n",
    "print(max(l),\"is the greatest score from 10**\",nums[l.index(max(l))])\n",
    "print(\"We can drop all features whose coeffs are less than our confidence interval\")\n",
    "print(\"Really big values of C are most similar to un-regularized model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify a classification problem related to your final project, using your project data.  \n",
    "\n",
    "1. Apply $L^2$ regularized logistic regression to model this with an appropriate choice of $C$ (or lambda).  Discuss how (and why) you chose your specific the value $C$.  \n",
    "2. Apply $L^1$ regularized logistic regression to model this with an appropriate choice of $C$.  Discuss how (and why) you chose your specific value of $C$.  \n",
    "3. Identify which features of your data to include and which to discard for a good logistic regression model for your problem.  Compare which features are suggested for removal by $L^1$ regularization (from `scikit-learn) versus using the methods we have used for linear regression, including p-values, BIC, and AIC (from statsmodels).  \n",
    "Clearly identify your final preferred model, and explain why you chose that over the other contenders. \n",
    "What conclusions can be drawn from your results about the original classification question you asked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../../Desktop/yelpcrawl/yelp.csv\", names=['name','category','rating','address','price','0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data[['name','category','rating','address','price']]\n",
    "data=data.drop_duplicates()\n",
    "data.to_csv('yelp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>address</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Las Incas</td>\n",
       "      <td>Peruvian</td>\n",
       "      <td>None</td>\n",
       "      <td>279 E 300 S StProvo UT 84606</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Gandolfo's New York Deli</td>\n",
       "      <td>American(Traditional)Delis</td>\n",
       "      <td>4</td>\n",
       "      <td>715 S Main StPleasant Grove UT 84062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Sushi Garden Bistro</td>\n",
       "      <td>SushiBars</td>\n",
       "      <td>4</td>\n",
       "      <td>192 S 500th EAmerican Fork UT 84003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>Chick-fil-A</td>\n",
       "      <td>FastFood</td>\n",
       "      <td>4</td>\n",
       "      <td>183 N West State RdAmerican Fork UT 84003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Molly's</td>\n",
       "      <td>American(Traditional)</td>\n",
       "      <td>4.5</td>\n",
       "      <td>753 W Columbia LnProvo UT 84604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name                     category rating  \\\n",
       "750                 Las Incas                     Peruvian   None   \n",
       "457  Gandolfo's New York Deli   American(Traditional)Delis      4   \n",
       "408       Sushi Garden Bistro                    SushiBars      4   \n",
       "647               Chick-fil-A                     FastFood      4   \n",
       "235                   Molly's        American(Traditional)    4.5   \n",
       "\n",
       "                                        address  price  \n",
       "750                279 E 300 S StProvo UT 84606   None  \n",
       "457        715 S Main StPleasant Grove UT 84062      1  \n",
       "408         192 S 500th EAmerican Fork UT 84003      1  \n",
       "647   183 N West State RdAmerican Fork UT 84003      1  \n",
       "235             753 W Columbia LnProvo UT 84604      1  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data[data['price']!=' None']\n",
    "data=data[data['price']!='3']\n",
    "data=data[data['rating']!=\" None\"]\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(data[['rating']], data['price'], test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The purpose of this is to see if there's a correlation between restaurant price (\\$ vs \\$\\$) and Yelp rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for L2 regression is  0.734375  with C=10^-10, which was chosen by looping through like above\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(penalty=\"l2\",C=10**-10)\n",
    "results = log.fit(Xtrain, ytrain)\n",
    "score = results.score(Xtest, ytest)\n",
    "print(\"Score for L2 regression is \", score, \" with C=10^-10, which was chosen by looping through like above\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734375 is the greatest score from 10** -10\n",
      "The same value of C was used in this regression. After running the code several times, I've determined L1 vs L2 makes no difference on this data\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "nums=range(-10,11)\n",
    "for i in range(-10,11):\n",
    "    log = LogisticRegression(penalty=\"l1\",C=10**i)\n",
    "    results = log.fit(Xtrain, ytrain)\n",
    "    l.append(results.score(Xtest, ytest))\n",
    "print(max(l),\"is the greatest score from 10**\",nums[l.index(max(l))])\n",
    "print(\"The same value of C was used in this regression. After running the code several times, I've determined L1 vs L2 makes no difference on this data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was a little bit difficult to work with because most of what I want to predict is dependent on the category tags, so there's less numerical data to work with. Hence only rating and price were compared. That could be why L1 and L2 gave the same answers each time.\n",
    "I imagine since this was only contingent on one variable that none of the models would suggest removing it. I prefer logistic regression because we spent more than 5 minutes on it in class so I feel like I understand it more. Maybe that's a bad reason.....\n",
    "\n",
    "After running the regression, we can determine that there is a correlation between price and perceived quality of a restaurant, but it doesn't hold true all the time. People prefer expensive things, but McDonald's is still pretty great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_categories(string):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
